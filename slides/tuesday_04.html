




<!DOCTYPE html>
<html>
  <head>
    <title>Digital Summer School 2024: Tuesday Morning</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" href="../style.css">  </head>
  <body>
    <textarea id="source">

class: center, middle, titlepage
### TUE04: *Fixity and storage.*

---
class: contentpage
### **Agenda**


      
1. Intro to Hashing/Checksums (Paul)
2. Streamhashing, whole file hashing, types of checksum algorithms. (Jo)
3. Lossless framemd5 frame level checksums. (Jo)
4. FFV1 checksums at slice level. (Jo)
5. Python hashlib. (Paul)
6. Perceptual hashing, visual similarity matching. (Paul)
7. Bagit for Python. (Paul)
8. TAR wrapping with CLI 'tar' or Python 'tarfile'. (Paul)

      


---
class: contentpage

### **1. Intro to Checksums**

Checksums are "fixed width" (ie always the same length) digital fingerprints.

They can be generated from text or files!

MD5 for the string "Paul Duchesne"!

```sh
echo -n "Paul Duchesne" | md5sum
0396b497d1949e210d09692607734e97
```

MD5 for a jpg image file!

```sh
md5sum test.jpg
4a4d8a9873aa2194c658803c4c67744e
```

TODO equivalent commands on different OSs    
TODO also replace all the examples with macOS syntax

---
class: contentpage

### **1. Intro to Checksums**

An important concept of checksums is that they are predictable, with the same input they will produce the same output every time.

```sh
echo -n "Paul Duchesne" | md5sum
0396b497d1949e210d09692607734e97
```

```sh
echo -n "Paul Duchesne" | md5sum
0396b497d1949e210d09692607734e97
```

```sh
echo -n "Paul Duchesne" | md5sum
0396b497d1949e210d09692607734e97
```
```sh
echo -n "Paul Duchesne" | md5sum
0396b497d1949e210d09692607734e97
```


---
class: contentpage

### **1. Intro to Checksums**

However, any slight change in the input will, using the most popular checksumming types found in digital archiving, produce a completely different output.

```sh
echo -n "Paul Duchesne" | md5sum
0396b497d1949e210d09692607734e97
```

```sh
echo -n "paulduchesne" | md5sum
9a464f6d1e4bf783d7c5c48143c92d87
```
```sh
echo -n "Paul Duchesne" | md5sum
0396b497d1949e210d09692607734e97
```

```sh
echo -n "paulduchesne" | md5sum
9a464f6d1e4bf783d7c5c48143c92d87
```

---
class: contentpage

### **1. Intro to Checksums**

Checksums are not reversible, you cannot recreate the source from the checksum, but you can verify if the source is unchanged.

These characteristics mean this concept is used extensively in net and digital security.

Example process: a user to a system (eg a website, database) creates a password, the system only stores the checksum.

```sh
echo -n "my_cool_password" | md5sum
a873aee995ffc1fe2634e63560d3aabb
```

When the user wants to log in again, they will re-enter their password which should generate the same checksum... result: they can log in!

If a hacker steals the checksums (the only element the system has retained) they do not automatically know what the source password was, so they can't login.

If the checksum algorithm (so far we have been using MD5) is not complex enough, the hacker may start trying to find a password which matches the checksum (eg a list of common passwords) or even "brute force" (eg "a", "aa", "aaa", "aaaa" etc etc etc) until they get a password which matches the checksum.

---
class: contentpage

### **1. Intro to Checksums**


Note on terminology, generally "hashes" are used in the context of digital security/authentication and "checksums" for checking file fixity, but both use the same concept and are generally used interchangeably.

"File fixity" meaning that the file is fixed, unchanged, which is obviously a key concern for digital archives.


---
class: contentpage

### **1. Intro to Checksums**

One key difference between the use of these technologies for security and for digital archiving is that digital archiving is mostly concerned with accidental breakage (file truncation) while net security is dealing with intentional malicious behaviour (hackers). This means archives generally are using what would be considered "out of date" hashing algorithms.

MD5, which we have seen so far, is pretty ubiquitous in the digital preservation community. It has been around since 1991 and is considered "good enough"



What we mean by "good enough" - our main concern here are "collisions", where two different sources generate the same hash. What are the odds!

---
class: contentpage

### **1. Intro to Checksums**



There are `340,282,366,920,938,463,463,374,607,431,768,211,456` possible MD5 hashes, sounds pretty good! 

But once we factor in "The Birthday Paradox", the chance of a single collision is 50% every `18,446,744,073,709,551,616` hashes.

Birthday Paradox tangent: https://pudding.cool/2018/04/birthday-paradox/

MD5 is "good enough" for archives, in that it there are currently no AV archives holding this many files (not even close).

---
class: contentpage

### **1. Intro to Checksums**

A downside of using MD5 is that it can be quite slow to hash files, which can add up if you are generating checksums across an entire system.

Modern hashing functions like xxhash claim to be around 50 times faster.

https://github.com/Cyan4973/xxHash



---
class: contentpage

### **2. Streamhashing, whole file hashing, types of checksum algorithms**

---
class: contentpage

### **3. Lossless framemd5 frame level checksums**

---
class: contentpage

### **4. FFV1 checksums at slice level**

---
class: contentpage

### **5. Python hashlib**

As we saw before, we can generate hashes directly from the command line, but there are reasons we might want to do this in Python. For example, as part of a more complex media processing script, or if we want to hash a large directory of files and find where there are matches in a database.

We could use subprocess, but Python already comes with a handy inbuilt library called `hashlib`.

Example of hashing a string

```python
import hashlib
source = "Paul Duchesne"
result = hashlib.md5(source.encode()).hexdigest()
print(result)
```

TODO make note that "encode" is transforming from text to binary.

---
class: contentpage

### **5. Python hashlib**

Example of hashing a file.

```python
import hashlib
import pathlib

filepath = pathlib.Path.cwd() / 'test.jpg'

with open(filepath, 'rb') as file:  
    file_content = file.read()  
    result = hashlib.md5(file_content).hexdigest()  
    print(filepath, result)
```

---
class: contentpage

### **5. Python hashlib**

Example of hashing two files, and checking if they match.

Note, we have condensed our code slightly, but it is doing exactly the same thing.

TODO adapt to use film scan frames

```python
import hashlib
import pathlib

filepath1 = pathlib.Path.cwd() / 'test.jpg'
with open(pathlib.Path.cwd() / 'test.jpg', 'rb') as file:    
    result1 = hashlib.md5(file.read()).hexdigest()  
    print(filepath1, result1)

filepath2 = pathlib.Path.cwd() / 'test.py'
with open(filepath2, 'rb') as file:    
    result2 = hashlib.md5(file.read()).hexdigest()  
    print(filepath2, result2)

print(result1 == result2)
```
Okay, but say we want to hash the files in an entire directory! We don't want to have to create individual statement for each file.

---
class: contentpage

### **5. Python hashlib**

Exmample of hashing multiple files (TODO use film scan frames) in a "for loop", 

```python
import hashlib
import pathlib

for filepath in ['test.txt', 'test2.txt']:

    with open(pathlib.Path.cwd() / filepath, 'rb') as file:  
        result = hashlib.md5(file.read()).hexdigest()  
        print(filepath, result)
```

Okay, better, but we don't want to have to write out all the file names!


---
class: contentpage

### **5. Python hashlib**

Example of processing a whole directory (TODO use film scans)

```python
import hashlib
import pathlib

for filepath in pathlib.Path.cwd().iterdir():

    with open(filepath, 'rb') as file:  
        result = hashlib.md5(file.read()).hexdigest()  
        print(filepath, result)
```


---
class: contentpage

### **6. Bagit for Python**

BagIt is an open source, multiplatform solution developed by Library of Congress to provide structures and tools typically to verify that collections of files remain unchanged.

You could absolutely write your own Python scripts to create, store and validate checksums, BagIt is just a conveniance method for fundamental digital archiving processes. 

If you want to create a "bag" as a one-off we can just use the Python script provided by LOC:

```sh
bagit.py /directory/to/bag
```

If we want to do something more complex we will want to write Python code which uses their Python code ourselves, which can be imported as a library.


---
class: tangentpage

### **Tangent 1: installing external libraries.**

Now, unlike the other libraries we have looked at today, BagIt is not pre-installed with Python (start a petition!), so we have to install it ourselves.

The easiest way to do this is via pip.



```python
import bagit
```

If we don't have the 'bagit' library installed we will get a `ModuleNotFoundError: No module named 'bagit'` error in Python.

We can check out libraries using `pip freeze` to verify that this is true!

Installing

```sh
pip install bagit
```

TODO also not that we can specify a version

import bagit should work.



---
class: tangentpage

### **Tangent 1: installing external libraries.**


Just be aware that we are now running other peoples code on our machines, there no 100% that they have not programmed it to do something we do not want them to do.
From a security perspective worth considering installing libraries which either have a lot of "stars" on GitHub, or are from people or organisations we trust (like Library of Congress).


---
class: tangentpage

### **Tangent 2: managing requirements.**

Now that we have started installing our own packages we have drifted away from the default experience of a fresh Python install.

We might have a project which require twenty external libaries, and we want other people to know about these and to be able to install them themselves.

We can track these in a `requirements.txt` file.

```
example
```

This way we can install all of the required packages in one go, and specific versions.

```
pip install -r requirements.txt
```


---
class: tangentpage

### **Tangent 3: virtual enviroments.**

Installing those libraries is in pursuit of creating the same enviroment, so that code which runs should behave the same.

But we can have multiple projects which require different versions of the same library, for example Project 1 need library 2.5 but Project 2 needs library 3.4.

Virtual enviroments let us manage the python libraries per project, which is pretty cool.


```sh
virtualenv venv -p 3.10
source venv/bin/activate
pip install -r requirements.txt
python app.py
```

---
class: contentpage

### **6. Bagit for Python**

Practical: BagIt for film scans

Bagit security features


---
class: contentpage

### **7. TAR wrapping with CLI 'tar' or Python 'tarfile'**

Great, so we have our "bag", now what do we do with it?

Generally speaking most archives would then "wrap the bag". 
Many archives use TAR, which is a very old option (1979) and widely supported means of wrapping files for storage or transport.


as you have probably many times, we can eaither create tars from the command line on a unix-machine (linux/mac) or using python (os agnostic)

Python has an inbuilt `tarfile` library!

Practical: TAR wrap bagit

Practical: untar






---
class: contentpage

### **8. Perceptual hashing, visual similarity matching**

perceuptuial hashing has a different purpose, and worth introducing as a concept
while checksum hashing for file validation is ubiqisuot, hashing for content similarity is more unusal and only a few institutions are doing (eg?)

do in Python?

example similar strings return similar hashes

example simialr images return similar hashes

where would this be useful for an archive, similarity detection

say someone gives you digital material, it is useful to be able to check if it is already in your collection, but any slight change precludes you from checking

perceptual hashes allow to find where the is content overlap, even if the file itself is slightly different



    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({ratio: "16:9"});
    </script>
  </body>
</html>
