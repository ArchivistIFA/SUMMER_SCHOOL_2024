
<!DOCTYPE html>
<html>
  <head>
    <title>Digital Summer School 2024: Tuesday Morning</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" href="../style.css">  </head>
  <body>
    <textarea id="source">

class: center, middle, titlepage
### WED01: *FFmpeg video encoding, filters and QC Tools*
---
class: contentpage
### **Agenda**

FFmpeg video encoding  
> 1.1 Lossy vs Lossless compression  
> 1.2 Bitrate  
> 1.3 Bit-depth  
> 1.4 Chroma subsampling and colourspaces     
> 1.5 Lossless encoding examples  
> 1.6 Lossy encoding examples  
> 1.7 Other interesting FFmpeg commands

FFmpeg filters  
> 2.1  

QC Tools  
> 3.1  

---
class: contentpage
### **1. FFmpeg video encoding**

Why do we need to encode?

- To save storage space
- To optimise video quality
- To make adaptable access files
- To maintain accessibility to obsolete codecs over time

The FFmpeg team reverse engineer virtually every video and audio codec that exists. We're incredibly lucky to have an open-source tool like FFmpeg to help with codec obsolescence and encoding/decoding. Obsolete formats saved by FFmpeg:   
- Cinepak  
- RealVideo    
- QuickTime 4    
- Flash Video  

FFmpeg allows for granular encoding choices that include encoding libraries, chroma subsampling, colourspace, bit-depth and bitrate.  
```sh
ffmpeg -f lavfi -i testsrc=size=720x576 -c:v v210 -f lavfi
-i "sine=frequency=1000:sample_rate=48000" -c:a pcm_s16le -t 10 test_file.mov
```

???
We need to use lossless and lossy compression codecs for creation of preservation masters and access copies. 
- Cinepak - a lossy video codecs released in 1991 and incorporated into Apple’s QuickTime video suite in 1992.  
- RealVideo was first released in 1997 and was crucial in introducing the concept of internet-based audio and video to consumers.  
- QuickTime 4 was released in 1999. Apple collaborated with a firm called Sorenson who specialised in video codecs and together launched a format that became hugely popular for streaming film trailers.  
- Flash Video is a container file format used to deliver digital video over the internet using Adobe flash player. The codecs flv and f4v were often paired with Sorenson and VP4 video codecs.  

---
class: contentpage
### **1.1 Lossy vs Lossless compression**

SPARE:

```
 Process           | Lossless codecs                   | Lossy codec                           
 ----------------- | --------------------------------- | -----------------------------------     
 Algorithm         | Reduces file size but not quality | Reduces size by discarding data       
 Reversibility     | Compression can be reversed       | Cannot be reversed                    
 Compression ratio | Lower compression ratios          | Higher compression ratios             
 Quality           | Maintains original video quality  | Reduces video quality, configurable   
 Use cases         | Archives / where quality required | Access copies for web / other media   
 Examples          | FFV1, DPX, H.264, TIFF, FLAC      | H.264, MPEG, DV, JPEG, AAC, MP3       
```

---
class: contentpage
### **1.1 Lossy vs Lossless compression**

Codecs that use lossy compression reduce the size of a file by discarding some of the redundant information from the original video stream. This process cannot be reversed and the original data is cannot be retrieved.  

.left[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/wednesday/images/Screenshot 2024-08-28 at 21.00.09.png" width="900">]

```sh
ffmpeg -i uncompressed.mov -map 0 -c:v libx264 -crf 18 -c:a aac lossy.mp4
```
---
class: contentpage
### **1.1 Lossy vs Lossless compression**

Lossless compression reduces the size of a video file without losing any information or quality. These algorithms preserve the original data in the video stream, and decompression returns a bit perfect copy of the original.

.left[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/wednesday/images/Screenshot 2024-08-28 at 20.59.37.png" width="900">]
```sh
ffmpeg -i uncompressed.mov -map 0 -dn -c:v ffv1 -level 3 -g 1 -c:a copy lossless.mkv
```
---
class: contentpage
### **1.1 Lossy vs Lossless compression**

Group of Picture (GOP) length 1 determines that every file is a key frame and that no image data is discarded 
```sh
ffmpeg -i lossless.mov -c:v libx264 -map 0 -g 1 -c:a copy h264_gop1.mp4
ffmpeg -i lossless.mov -c:v libx264 -map 0 -g 12 -c:a copy h264_gop12.mp4
```

GOP=1 will reduce the file size with H.264 I frame compression, but you won't create any B/P frames. The default GOP in FFmpeg is 12.  

<font color="orange">Practise:</font> Make two conversions of a lossless video with GOP=1 and GOP=12 setting. Then use this command to view the GOP settings in FFprobe:  
```sh
ffprobe -v error -show_entries frame=pict_type -of default=nw=1 file.ext
```
---
class: contentpage
### **1.2 Bitrates**

Bit rates control the quality of the video compression, which in turn alters the size of your file dramatically. You may have heard of Constant Bit Rate (CBR) and Variable Bit Rate (VBR). VBR generally gives better overall quality when file size and bit rate are not constrained.  

Constant Rate Factor give you a consistent quality through your encoding for one pass. You can set it for all your transcodes and let the encoder make the adjustments needed between files:
```sh
ffmpeg -i input.mov -c:v libx264 -crf 23 output.mp4
```
The CRF scale for H264 is 0-51. 0 is best, 23 is default and 51 worst. The `sane` range is considered to be 17-28 for visually lossless encoding. The CRF method is consider best for archival formats, as you can guarantee the quality you want though not the file size. Not recommend for streaming.
 
There are presets and tuning options for this encoder to help fine tune your encoding results:
- `-preset` ultrafast, superfast, veryfast, faster, fast, medium (default), slow, slower, veryslow
- `-tune` film, animation, grain, stillimage, fastdecode, zerolatency

Slower presets allow for better compressions, and film which lowers deblocking for high quality movie content:  
```sh
ffmpeg -i input.mov -c:v libx264 -present slow -tune film -crf 23 output.mp4
```
???
More details can be found on the [FFmpeg wiki for H.264 encoding](https://trac.ffmpeg.org/wiki/Encode/H.264)
Bitrates control the quality of the video compression, which in turn alters the size of your file dramatically. Constant Bit Rate (CBR) uses the same amount of bits across all frames when needed and Variable Bit Rate (VBR) allows the encoder to use more bits for difficult scenes (complex texture or high motion), saving bits for the easy parts of the files to compress.

Rate control varies between codecs in FFmpeg,  but we can look at example such as H.264 to understand it more - selected by the libx264 library
---
class: contentpage
### **1.2 Bitrates**

If you want to target a specific file size for your bitrate encodings you can use Two-Pass you can specify it using -b:v for video bitrate:  
```sh
ffmpeg -y -i input.mov -c:v libx264 -b:v 2600k -pass 1 -an -f null /dev/null && \
ffmpeg -i input.mov -c:v libx264 -b:v 2600k -pass 2 -c:a aac -b:a 128k output.mp4
```
It's a two pass process and you need to export the first pass to a local file using `-f null /dev/null`. A file named `ffmpeg2pass-0.log.mbtree` will appear in your `pwd`. The second pass will read this file and calculate the required bitrate for the MP4 creation. 

Lossless bitrates:

It's possible to use `-crf 0` for lossless H.264 High 4:4:4 Predictive encoding. For other H.264 lossless encoding use '-qp 0', FFmpeg's Quantization Parameter:
```sh
ffmpeg -i input.mov -c:v libx264 -preset veryslow -qp 0 output.mkv
```

<font color="orange">Practise:</font> Try creating a lossless H.264 file from a lossless source. Make and compare Framemd5 files for the two using the `-an` flag to just compare video streams. See what the size differences are.
???
Quantization Parameter controsl amout of compression for every macroblock in a frame, range from 0-51 in H264. Best just used for lossless.
---
class: contentpage
### **1.3 Bit depth**

This is my lovely cat Eisenstein on the left in 8 bit greyscale. The image on the right is at 4-bit. The left 8-bit curve is smoother than the 4-bit curve where less bits are available to describe the tones of the analogue wave.  

.left[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/wednesday/images/4_8_bit_eisey.png" width="1000">]

For an RGB file this would be 8-bits for red, 8-bit for green and 8-bit for blue components.  
And for YUV, 8-bit for Y luminance, and 8-bit each for U and V chrominance.  
 
- 8-bit: 256 bits per sample (256 variations)  
- 10-bit: 1024 bits per sample (1024 variations)  
- 12-bit: 4096 bits per sample (4096 variations)  
- 16-bit: 65536 bits per sample (65536 variations)  
???
4-bit has only 16 bits per samples, so 16 gradation changes
---
class: contentpage
### **1.4 Chroma subsampling and colourspaces**

.left[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/wednesday/images/chroma_subsampling.png" width="1000">]

Chroma subsampling is an alternative way to encode your colour media. The process is lossy and only compresses chroma (colour) data, not the luminence (brightness). You'll be familiar with some of these ratios:  
> 4:4:4 is chrominance sampled at the same rate as luminance (no compression)  
> 4:2:2 is chrominance sampled at half the rate of luminance (the compression ~ 1/3 smaller than 4:4:4)  
> 4:2:0 and 4:1:1 is chrominance sampled at half the rate (the compression ~ half the size of 4:4:4) 

You’ve probably seen some chroma subsampling values described as four part ratios, 4:2:2:4, where this is the case the final number 4 refers to the sampling of the alpha channel.  
---
class: contentpage
### **1.4 Chroma subsampling and colourspaces**

.center[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/wednesday/images/Screenshot 2024-08-28 at 17.19.31.png" width="900">]
.center[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/wednesday/images/Screenshot 2024-08-28 at 17.19.12.png" width="900">]
 > > Source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Barn-yuv.png)
---
class: contentpage
### **1.3 Chroma subsampling and colourspaces**

.left[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/wednesday/images/Screenshot 2024-08-28 at 17.24.09.png" width="620">]

---
class: contentpage
### **1.4 Chroma subsampling and colourspaces**

Colourspace, bit-depth and chroma subsampling are selected in FFmpeg using the Pixel Format:    
- `-pix_fmt yuv422p10le`: YUV colourspace, 4:2:2 chroma subsampling, 10 bit-depth, little endian  
- `-vf format=yuv420p`: The video filter `format` can also apply Pixel Format options  

The most common pix_fmts for video include:  
- 8-bit 4:2:0  -  yuv420p  
- 8-bit 4:2:2  -  yuv422p   
- 10-bit 4:2:2  - yuv422p10le  
- 10-bit 4:4:4  - yuv444p10le  

You can view all available with the `-pix_fmts` advanced help option: 
```sh
ffmpeg -pix_fmts
ffmpeg -i input.mkv -c:v v210 -pix_fmt yuv422p10le output.mov
ffmpeg -i input.mov -c:v libx264 -vf format=yuv420p output.mp4
```
<font color="orange">Practise:</font> View available Pixel Formats in FFmpeg and try re-encoding your file to a different pix_fmt.  

???
NOTE: Pixel formats change between FFmpeg version releases based on development of the libraries. This is the cause of Framemd5 file differences between FFmpeg version releases, as the pix_fmt settings for the codec are used to decompress to raw video for framemd5 creation. Framemd5s are not long-term fixity.
---
class: contentpage
### **1.4 Colourspace and models**

You can also embed colorspace metadata to your encodings using These FFmpeg commands:  
- color_primaries selecting the colour model to be tagged with.  
  FFmpeg values include: smpte170m (REC.601 NTSC), bt470bg (REC.601 PAL), bt709 (REC.709/sRGB), bt2020 (REC.2020)  
- color_trc marks the video with transfer characteristics (gamma).  
  FFmpeg values include: smpte170m (REC.601 NTSC), gamma28 (REC.601 PAL), bt709 (REC.709/sRGB), bt2020_10 / _12 (REC.2020 10-bit/12-bit)  
- colorspace marks the video for having the given colourspace.  
  FFmpeg values include: smpte170m (REC.601 NTSC), bt470bg (REC.601 PAL), bt709 (REC.709/sRGB), bt2020_cl / _ncl (REC.2020 constant/non-constant luminance) 
 
You can use the video filter colormatrix to change one colourspace to another, for example bt709 to bt2020 only:  
```sh
ffmpeg -i input.mov -vf colormatrix=bt709:bt2020 output.mov
```

<font color="orange">Practise:</font> Try to change a colour space to another using the video filter colormatrix, or appending/amending existing colour metadata in some of your test files.    
```sh
ffmpeg -i input.mov -color_primaries bt2020 -color_trc bt2020_10 -colorspace bt2020_cl output.mov
```

---
class: contentpage
### **1.5 Lossless video encoding examples**

Encoding FFV1 Matroska to V210 MOV losslessly  
```sh
ffmpeg
-i input.mkv
-map 0
--movflags write_colr
-c:v v210
-pix_fmt yuv422p10le 
-color_primaries bt709
-color_trc bt709
-colorspace bt709
-color_range mpeg 
-metadata:s:v:0 "encoder=Uncompressed 10-bit 4:2:2"
-c:a copy
-vf setfield=tff,setdar=16/9
-f mov output.mov
```

This is our BFI command that encodes FFV1 Matroska files to V210 Mov files with metadata that matches an Apple Quicktime V210 MOV. It has MOV specific requests like movflags, encoder metadata and the -f mov flag.  

You can add these two commands after your output.mov to create a FrameMD5 of the transcode simultaneously.  
```sh
-f framemd5 -an output.framemd5
```
---
class: contentpage
### **1.5 Lossless video encoding examples**

Encoding V210 MOV to FFV1 Matroska losslessly 
```sh
ffmpeg
-i input.mov
-map 0 -dn
-c:v ffv1
-level 3
-g 1
-slicecrc 1
-slices 24
-pix_fmt yuv422p10le 
-color_primaries bt709
-color_trc bt709
-colorspace bt709
-color_range 1 
-c:a copy
-vf setfield=tff,setdar=4/3
output.mkv
```
The -map command this time has a -dn which tells FFmpeg not map any data streams to the Matroska. The FFV1 codec has a number of options to create your best lossless encoding, including level 3 (the latest version release), gop 1, slicecrc active, slices 24 per frame.  

---
class: contentpage
### **1.5 Lossless video encoding examples**

DPX sequence in a folder to JPEG2000 wrapped in an MXF:  
```sh
ffmpeg -y -framerate 24 -i \PATH\test\0%05d.dpx -c:v libopenjpeg -pix_fmt gbrp10le 123.mxf

```
---
class: contentpage
### **1.6 Lossy video encoding examples**
---
class: contentpage
### **1.7 Other FFmpeg commands**

To run some experiments lets make a 10 second audiovisual file using FFmpeg lavfi filters as your inputs  
```sh
ffmpeg -f lavfi -i testsrc=size=1920x1080 -f lavfi -i "sine=frequency=1000:sample_rate=48000"
-t 10 input.mov
```
You can trim video down to specific time code start and stops, and encode the output  
```sh
ffmpeg -ss 00:00:10.000 -i input.mov -to 00:00:25.000 -c:v libx264 -c:a aac output.mp4
```
You can export one thumbnails every frame between 1 and 2 seconds and save them as `png` files  
```sh
ffmpeg -i input.mov -vf select=`between(t,1,5)` -vsync 0 output_images%d.png 
```
Mute audio in a video file, between two time codes  
```sh
ffmpeg -i input.mov -c:v copy -af “volume=enable=‘between(t,3,5)':volume=0" input_muted.mov
```
---
class: contentpage
### **1.7 Other FFmpeg commands**

Convert an image sequence, such as your DPX sequence into a lossy ProRes 4:4:4 MOV file with framerate 25 fps 
```sh
cd <dpx_folder>
ffmpeg -f image2 -pattern_type glob -i “*.dpx” -c:v prores_ks -profile:v 4 
-pix_fmt yuv444p10le -r 25 your_dpx_file.mov
```


---
class: contentpage
### **2. FFmpeg video filters**


    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({ratio: "16:9"});
    </script>
  </body>
</html>
