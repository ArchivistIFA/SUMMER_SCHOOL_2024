<!DOCTYPE html>
<html>
  <head>
    <title>Digital Summer School 2024: THU04</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" href="../style.css">  </head>
  <body>
    <textarea id="source">


class: center, middle, titlepage
### THU04: *Multiprocessing, Logging, Containerisation, Orchestration.*




Note to Paul, write out the whole doc as markdown before worrying about segmenting and agenda, do this last.


~

This afternoon we are going to look at some more advanced Python topics, specifically Mutliprocessing and Logging.

We are then going to look at running Python in some different enviroments, and finally conatinerisation and orcheestration.


Multiprocessing refers to the fact that Python generally runs on a single processor, and if we are trying to do a lot of processing we want to use all of the computational power at our disposal.

To illusatrate this we can open up our activity monitor and observe activity.

Worth noting that most laptops have limited resources, so a possible pathway is to refine a process on your own machine and then trasnfer to serious multicore desktop machine.

The goal here is that if a process takes a certain period of time, if you can effitenly multiprocess on a 64-core machine, the proceess will run 64 times faster.

There is a big difference between 1 day and 64 days, or 1 year and 64 years!!!

Python has a handy multiprocessing library called "multiprocessing".

The first thing we would want to do is so how many processors our computer has to give some idea of how we allocate resources.

```python
import multiprocessing
multiprocessing.cpu_count() 
```

We can now define a task in Python, and then organise for it to run in batches,

The Pool method makes allocating tasks in batches quite easy, but note that all results will be returns when the longest finishes.

```python
import multiprocessing
import time

def my_process(file_name):
    print(f"{file_name} has started.")
    time.sleep(10) 
    print(f"{file_name} has ended.")

if __name__ == "__main__":

    files = ['file_01', 'file_02', 'file_03', 'file_04']
    
    p = multiprocessing.Pool()
    with p:
        p.map(my_process, files)

    print("All processes have finished.")
```

There a few new components we can see here!

The def name() constructoon in Python is what we can a function, which is common way to group a block of code we want to reuse to do the same thing over and over, often with different inputs.

This is perfect for multiprocessing where we want to define a single block of code which gets executed in different processes at the same time.

The `if __name__ == "__main__":` part is a way of making sure that the python script is being executed directly, and not being imported into other code.

The behaviour we will observe here is that four processes are actioned simultaneously, which are to "sleep" (do nothing) for ten seconds, and the results are all returned at the same time.


Multiprocessing is extremely useful if you have "expensive" operations (like file operations, eg hashing) which are causing you to wait for your script to execute. It does however introduce extra complexity to your scripts so should only be used if requried.



~

Logging is an important feature when we build a complex pipeline and something goes wrong, or we even want to check up on where systems are at.

Python has an inbuilt logging feature which is quite similar to the "print" statements, but intended to report activity. Another difference is they are written to disk, whereas print statements are "ephemeral".

Logging is extremely useful if you ever get asked the questions: when did you exactly transcode that file? How long did it take? What was the output?

LOGGING examples.



~

Containerisation refers to the process of encapusltaing an enviroment to ensure that systems run predictably. Why would you do this? Quite simply because every computer in the world, once it has been used for a sginicant period of time, becomes its own enviroemnt, Files sit in different locations, applications are installed or removed, etc. There are also inherent differences we have seen on different applications.

Docker is uniqiiouts in this space, but Podman also has some benefits around security considerations.

CONATINER example.


~

The last topic for today is orchestration. We have covered writing and scheduling individual tasks, which is fine if you are running one or two handfuls of processes. Once you scale up to fifty or a hundred distinct processes this can be hard to manage.

What we need then is a system to manage all of our processes, which is generally called an orchestrator. 

This is an ineteresing subject as I believe Joanna and I are both at the point where our own processes have only recently reached this moment, so these tools are new for us as well.

ORCH examples







    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js" type="text/javascript"></script>
    <script type="text/javascript">var slideshow = remark.create({ratio: "16:9"});</script>
  </body>
</html>